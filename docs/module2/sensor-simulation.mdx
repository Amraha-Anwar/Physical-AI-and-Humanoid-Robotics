---
sidebar_position: 3
title: "Sensor Simulation"
---

# Sensor Simulation

A robot that cannot sense is blind. We need to simulate the **RealSense D435i** and **IMU** defined in our Setup Guide.

## 3.1 Adding an IMU (Inertial Measurement Unit)

The IMU is the inner ear of the robot. It provides orientation (Quaternion) and acceleration data, critical for balance.

Add this to your URDF (usually inside the torso or head link):

```xml
<gazebo reference="imu_link">
  <sensor name="imu_sensor" type="imu">
    <always_on>true</always_on>
    <update_rate>100</update_rate>
    <visualize>true</visualize>
    <topic>imu</topic>
    <plugin filename="libgazebo_ros_imu_sensor.so" name="imu_plugin">
      <topicName>imu</topicName>
      <bodyName>imu_link</bodyName>
      <updateRateHZ>100.0</updateRateHZ>
      <gaussianNoise>0.001</gaussianNoise>
      <xyzOffset>0 0 0</xyzOffset>
      <rpyOffset>0 0 0</rpyOffset>
      <frameName>imu_link</frameName>
    </plugin>
  </sensor>
</gazebo>
```

## 3.2 Simulating the RealSense D435i

We simulate the depth camera using a standard depth sensor plugin.

```xml
<gazebo reference="camera_link">
  <sensor name="camera" type="depth">
    <update_rate>30</update_rate>
    <camera>
      <horizontal_fov>1.047</horizontal_fov>
      <image>
        <width>640</width>
        <height>480</height>
        <format>R8G8B8</format>
      </image>
      <clip>
        <near>0.1</near>
        <far>10.0</far>
      </clip>
    </camera>
    <plugin name="camera_controller" filename="libgazebo_ros_camera.so">
      <alwaysOn>true</alwaysOn>
      <updateRate>0.0</updateRate>
      <cameraName>camera</cameraName>
      <imageTopicName>color/image_raw</imageTopicName>
      <cameraInfoTopicName>color/camera_info</cameraInfoTopicName>
      <depthImageTopicName>depth/image_raw</depthImageTopicName>
      <depthImageCameraInfoTopicName>depth/camera_info</depthImageCameraInfoTopicName>
      <pointCloudTopicName>depth/points</pointCloudTopicName>
      <frameName>camera_link</frameName>
    </plugin>
  </sensor>
</gazebo>
```

## 3.3 Lidar (2D Laser Scan)

For navigation (Module 3), a 2D Lidar is often used for obstacle avoidance.

```xml
<gazebo reference="lidar_link">
  <sensor name="lidar" type="ray">
    <ray>
      <scan>
        <horizontal>
          <samples>720</samples>
          <resolution>1</resolution>
          <min_angle>-1.57</min_angle>
          <max_angle>1.57</max_angle>
        </horizontal>
      </scan>
      <range>
        <min>0.10</min>
        <max>10.0</max>
      </range>
    </ray>
    <plugin name="laser_controller" filename="libgazebo_ros_ray_sensor.so">
      <ros>
        <argument>~/out:=scan</argument>
      </ros>
      <output_type>sensor_msgs/LaserScan</output_type>
      <frame_name>lidar_link</frame_name>
    </plugin>
  </sensor>
</gazebo>
```

## 3.4 Verification

1.  Launch Gazebo with the updated model.
2.  Open a terminal and run:
    ```bash
    ros2 topic list
    ```
3.  *Success Criteria*: You should see:
    *   `/imu`
    *   `/camera/color/image_raw`
    *   `/camera/depth/image_raw`
    *   `/scan`

:::info Capstone Linkage
This sensor data is the input for the **Isaac ROS VSLAM** node in Module 3. Without realistic simulated noise (configured via `gaussianNoise`), our VSLAM algorithm might fail in the real world.
:::
